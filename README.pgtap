pgTAP 0.03
==========

pgTAP is a collection of TAP-emitting unit testing functions written in
PL/pgSQL and PL/SQL. It is based on the Test::More module distributed with
Perl 5. You could even consider it a port of sorts.

Installation
============

For the impatient, to install pgTAP into a PostgreSQL database, just do this:

    make
    make test PGDATABASE=template1
    make install
    make installcheck

If you encounter an error such as:

    "Makefile", line 8: Need an operator

You need to use GNU make, which may well be installed on your system as
'gmake':

    gmake
    gmake test PGDATABASE=template1
    gmake install
    gmake installcheck

If you encounter an error such as:

    make: pg_config: Command not found

Be sure that you have `pg_config` installed and in your path. If you used a
package management system such as RPM to install PostgreSQL, be sure that the
`-devel` package is also installed. If necessary, add the path to `pg_config`
to your `$PATH` environment variable:

    env PATH=$PATH:/path/to/pgsql/bin make && make test && make install

And finally, if all that fails, copy the entire distribution directory to the
`contrib/` subdirectory of the PostgreSQL source code and try it there.

If you want to schema-qualify pgTAP (that is, install all of its functions
into their own schema), set the `$TAPSCHEMA` environment variable to the name
of the schema you'd like, for example:

    make TAPSCHEMA=tap

The `test` target uses the included `pg_prove` Perl program to do its testing,
which requires that TAP::Harness, included in
[Test::Harness](http://search.cpan.org/dist/Test-Harness/ "Test::Harness on CPAN") 3.x. `pg_prove` supports a number of environment variables that you
might need to use, including all the usual PostgreSQL client environment
variables:

* `$PGDATABASE`
* `$PGHOST`
* `$PGPORT`
* `$PGUSER`

Once pgTAP has been built and tested, you can install it into a database:

    psql -d dbname -f pgtap.sql

If you want pgTAP to be available to all new databases, install it into the
"template1" database:

    psql -d template1 -f pgtap.sql

If you want to remove pgTAP from a database, run the `uninstall_pgtap.sql`
script:

    psql -d dbname -f uninstall_pgtap.sql

Both scripts will also be installed in the `contrib` directory under the
directory output by `pg_config --sharedir`. So you can always do this:

    psql -d template1 -f `pg_config --sharedir`/contrib/pgtap.sql

But do be aware that, if you've specified a schema using `$TAPSCHEMA`, it will
always be created and the pgTAP functions placed in it.

Running pgTAP Tests
===================

You can also distribute `pgtap.sql` with any PostgreSQL distribution, such as
a custom data type. For such a case, if your users want to run your test suite
using PostgreSQL's standard `installcheck` make target, just be sure to set
varibles to keep the tests quiet, start a transaction, load the functions in
your test script, and then rollback the transaction at the end of the script.
Here's an example:

    \set ECHO
    \set QUIET 1
    -- Turn off echo and keep things quiet.

    -- Format the output for nice TAP.
    \pset format unaligned
    \pset tuples_only true
    \pset pager

    -- Revert all changes on failure.
    \set ON_ERROR_ROLBACK 1
    \set ON_ERROR_STOP true
    \set QUIET 1

    -- Load the TAP functions.
    BEGIN;
    SET client_min_messages = warning;
    \i pgtap.sql

    -- Plan the tests.
    SELECT plan(1);

    -- Run the tests.
    SELECT pass( 'My test passed, w00t!' );

    -- Finish the tests and clean up.
    SELECT * FROM finish();
    ROLLBACK;

Of course, if you already have the pgTAP functions in your testing database,
you should skip `\i pgtap.sql` at the beginning of the script. If your
database does not already have PL/pgSQL installed, you'll need to add it to
the database before you load pgTAP. Just add these lines after the `\pset`
section and before the `\set` section:

    -- Create plpgsql if it's not already there.
    SET client_min_messages = fatal;
    \set ON_ERROR_STOP off
    CREATE LANGUAGE plpgsql;

Now you're ready to run your test script!

    % psql -d try -Xf test.sql
    1..1
    ok 1 - My test passed, w00t!

You'll need to have all of those variables in the script to ensure that the
output is proper TAP and that all changes are rolled back -- including the
loading of the test functions -- in the event of an uncaught exception.

Or save yourself some effort -- and run a batch of tests scripts at once -- by
using `pg_prove`. If you're not relying on `installcheck`, your test scripts
can be a lot less verbose; you don't need to set all the extra variables,
because `pg_prove` takes care of that for you:

    BEGIN;
    SET client_min_messages = warning;

    -- Plan the tests.
    SELECT plan(1);

    -- Run the tests.
    SELECT pass( 'My test passed, w00t!' );

    -- Finish the tests and clean up.
    SELECT * FROM finish();
    ROLLBACK;

Now run the tests. Here's what it looks like when the pgTAP tests are run with
`pg_prove`:

    % pg_prove -d try sql/*.sql
    sql/coltap.....ok     
    sql/hastap.....ok     
    sql/moretap....ok     
    sql/pg73.......ok     
    sql/pktap......ok     
    All tests successful.
    Files=5, Tests=216,  1 wallclock secs ( 0.06 usr  0.02 sys +  0.08 cusr  0.07 csys =  0.23 CPU)
    Result: PASS

Yep, that's all there is to it.

Description
===========

The purpose of pgTAP is to provide a wide range of testing utilities that
output TAP. TAP, or the "Test Anything Protocol", is an emerging standard for
representing the output from unit tests. It owes its success to its format as
a simple text-based interface that allows for practical machine parsing and
high legibility for humans. TAP started life as part of the test harness for
Perl but now has implementations in C/C++, Python, PHP, JavaScript, Perl, and
now PostgreSQL.

I love it when a plan comes together
------------------------------------

Before anything else, you need a testing plan. This basically declares how
many tests your script is going to run to protect against premature failure.

The preferred way to do this is to declare a plan by calling the `plan()`
function:

    SELECT plan( 42 );

There are rare cases when you will not know beforehand how many tests your
script is going to run. In this case, you can declare that you have no plan.
(Try to avoid using this as it weakens your test.)

    SELECT * FROM no_plan();

Often, though, you'll be able to calculate the number of tests, like so:

    SELECT plan( COUNT(*) )
      FROM foo;

At the end of your script, you should always tell pgTAP that the tests have
completed, so that it can output any diagnostics about failures or a
discrepancy between the planned number of tests and the number actually run:

    SELECT * FROM finish();

Test names
----------

By convention, each test is assigned a number in order. This is largely done
automatically for you. However, it's often very useful to assign a name to
each test. Would you rather see this?

      ok 4
      not ok 5
      ok 6

Or this?

      ok 4 - basic multi-variable
      not ok 5 - simple exponential
      ok 6 - force == mass * acceleration

The later gives you some idea of what failed. It also makes it easier to find
the test in your script, simply search for "simple exponential".

All test functions take a name argument. It's optional, but highly suggested
that you use it.

I'm ok, you're not ok
---------------------

The basic purpose of pgTAP--and of any TAP-emitting test framework, for that
matter--is to print out either "ok #" or "not ok #", depending on whether a
given test succeeded or failed. Everything else is just gravy.

All of the following functions return "ok" or "not ok" depending on whether
the test succeeded or failed.

### `ok( boolean, description )` ###
### `ok( boolean )` ###

    SELECT ok( :this = :that, :description );
  
This function simply evaluates any expression (`:this = :that` is just a
simple example) and uses that to determine if the test succeeded or failed. A
true expression passes, a false one fails. Very simple.

For example:

    SELECT ok( 9 ^ 2 = 81,    'simple exponential' );
    SELECT ok( 9 < 10,        'simple comparison' );
    SELECT ok( 'foo' ~ '^f',  'simple regex' );
    SELECT ok( active = true, name ||  widget active' )
      FROM widgets;

(Mnemonic:  "This is ok.")

The `description` is a very short description of the test that will be printed
out. It makes it very easy to find a test in your script when it fails and
gives others an idea of your intentions. The description is optional, but we
*very* strongly encourage its use.

Should an `ok()` fail, it will produce some diagnostics:

    not ok 18 - sufficient mucus
    #     Failed test 18: "sufficient mucus"

### `is( anyelement, anyelement, description )` ###
### `is( anyelement, anyelement )` ###
### `isnt( anyelement, anyelement, description )` ###
### `isnt( anyelement, anyelement )` ###

    SELECT is(   :this, :that, :description );
    SELECT isnt( :this, :that, :description );

Similar to `ok()`, `is()` and `isnt()` compare their two arguments with `=`
and `<>` respectively and use the result of that to determine if the test
succeeded or failed. So these:

    -- Is the ultimate answer 42?
    SELECT is( ultimate_answer(), 42, 'Meaning of Life' );

    -- foo() doesn't return empty
    SELECT isnt( foo(), '', 'Got some foo' );

are similar to these:

    SELECT ok(   ultimate_answer() =  42, 'Meaning of Life' );
    SELECT isnt( foo()             <> '', 'Got some foo'    );

(Mnemonic: "This is that." "This isn't that.")

*Note:* `NULL`s are not treated as unknowns by `is()` or `isnt()`. That is, if
`:this` and `:that` are both `NULL`, the test will pass, and if only one of
them is `NULL`, the test will fail.

So why use these? They produce better diagnostics on failure. `ok()` cannot
know what you are testing for (beyond the description), but `is()` and
`isnt()` know what the test was and why it failed. For example this test:

    \set foo '\'' waffle '\''
    \set bar '\'' yarblokos '\''
    SELECT is( :foo::text, :bar::text, 'Is foo the same as bar?' );

Will produce something like this:

    # Failed test 17:  "Is foo the same as bar?"
    #         have: waffle
    #         want: yarblokos

So you can figure out what went wrong without re-running the test.

You are encouraged to use `is()` and `isnt()` over `ok()` where possible.

### `matches( anyelement, regex, description )` ###
### `matches( anyelement, regex )` ###

    SELECT matches( :this, '^that', :description );

Similar to `ok()`, `matches()` matches `:this` against the regex `/^that/`.

So this:

    SELECT matches( :this, '^that', 'this is like that' );

is similar to:

    SELECT ok( :this ~ '^that', 'this is like that' );

(Mnemonic "This matches that".)

Its advantages over `ok()` are similar to that of `is()` and `isnt()`: Better
diagnostics on failure.

### `imatches( anyelement, regex, description )` ###
### `imatches( anyelement, regex )` ###

    SELECT imatches( :this, '^that', :description );

These are just like `matches()` except that the regular expression is compared
to `:this` case-insensitively.

### `doesnt_match( anyelement, regex, description )` ###
### `doesnt_match( anyelement, regex )` ###
### `doesnt_imatch( anyelement, regex, description )` ###
### `doesnt_imatch( anyelement, regex )` ###

    SELECT doesnt_match( :this, '^that', :description );

These functions work exactly as `matches()` and `imatches()` do, only they
check if `:this` *does not* match the given pattern.

### `alike( anyelement, pattern, description )` ###
### `alike( anyelement, pattern )` ###
### `ialike( anyelement, pattern, description )` ###
### `ialike( anyelement, pattern )` ###

    SELECT alike( :this, 'that%', :description );

Similar to `matches()`, `alike()` matches `:this` against the SQL `LIKE`
pattern 'that%'. `ialike()` matches case-insensitively.

So this:

    SELECT ialike( :this, 'that%', 'this is alike that' );

is similar to:

    SELECT ok( :this ILIKE 'that%', 'this is like that' );

(Mnemonic "This is like that".)

Its advantages over `ok()` are similar to that of `is()` and `isnt()`: Better
diagnostics on failure.

### `unalike( anyelement, pattern, description )` ###
### `unalike( anyelement, pattern )` ###
### `unialike( anyelement, pattern, description )` ###
### `unialike( anyelement, pattern )` ###

    SELECT unalike( :this, 'that%', :description );

Works exactly as `alike()`, only it checks if `:this` *does not* match the
given pattern.

### `cmp_ok( anyelement, operator, anyelement, description )` ###
### `cmp_ok( anyelement, operator, anyelement )` ###

    SELECT cmp_ok( :this, :op, :that, :description );

Halfway between `ok()` and `is()` lies `cmp_ok()`. This function allows you to
compare two arguments using any binary operator.

    -- ok( :this = :that );
    SELECT cmp_ok( :this, '=', :that, 'this = that' );

    -- ok( :this >= :that );
    SELECT cmp_ok( :this, '>=, 'this >= that' );

    -- ok( :this && :that );
    SELECT cmp_ok( :this, '&&', :that, 'this && that' );

Its advantage over `ok()` is that when the test fails you'll know what `:this`
and `:that` were:

    not ok 1
    #     Failed test
    #     '23'
    #         &&
    #     NULL

Note that if the value returned by the operation is `NULL`, the test will
be considered to have failed. This may not be what you expect if your test
was, for example:

    SELECT cmp_ok( NULL, '=', NULL );

But in that case, you should probably use `is()`, instead.

### `pass( description )` ###
### `pass()` ###
### `fail( description )` ###
### `fail()` ###

    SELECT pass( :description );
    SELECT fail( :description );

Sometimes you just want to say that the tests have passed. Usually the case is
you've got some complicated condition that is difficult to wedge into an
`ok()`. In this case, you can simply use `pass()` (to declare the test ok) or
`fail()` (for not ok). They are synonyms for `ok(1)` and `ok(0)`.

Use these functions very, very, very sparingly.

To Error is Human
-----------------

Sometimes you just want to know that a particular query will trigger an error.
Or maybe you want to make sure a query *does not* trigger an error. For such
cases, we provide a couple of test functions to make sure your queries are as
error-prone as you think they should be.

### `throws_ok( text, errcode, description )` ###
### `throws_ok( text, errcode )` ###
### `throws_ok( text )` ###

    SELECT throws_ok(
        'INSERT INTO try (id) VALUES (1)',
        '23505',
        'We should get a unique violation for a duplicate PK'
    );

When you want to make sure that an exception is thrown by PostgreSQL under
certain circumstances, use `throws_ok()` to test for those circumstances.

The first argument should be a string representing the query to be executed.
`throws_ok()` will use the PL/pgSQL `EXECUTE` statement to execute it and
catch any exception.

The second argument should be an exception error code, which is a
five-character string (if it happens to consist only of numbers and you pass
it as an integer, it will still work). If this value is not `NULL`,
`throws_ok()` will check the thrown exception to ensure that it is the
expected exception. For a complete list of error codes, see [Appendix
A.](http://www.postgresql.org/docs/current/static/errcodes-appendix.html
"Appendix A. PostgreSQL Error Codes") in the [PostgreSQL
documentation](http://www.postgresql.org/docs/current/static/).

The third argument is of course a brief test description.

Should a `throws_ok()` test fail it produces appropriate diagnostic messages.
For example:

    not ok 81 - simple error
    # Failed test "This should not die"
    #       caught: 23505: duplicate key value violates unique constraint "try_pkey"
    #       wanted: 23506

Idea borrowed from the Test::Exception Perl module.

### `lives_ok( text, description )` ###
### `lives_ok( text )` ###

    SELECT lives_ok(
        'INSERT INTO try (id) VALUES (1)',
        'We should not get a unique violation for a new PK'
    );

The inverse of `throws_ok()`, these functions test to ensure that a SQL
statement does *not* throw an exception. Should a `lives_ok()` test fail, it
produces appropriate diagnostic messages. For example:

    not ok 85 - simple success
    # Failed test "simple success"
    #         died: 23505: duplicate key value violates unique constraint "try_pkey"

Idea borrowed from the Test::Exception Perl module.

A Wicked Schema
---------------

Need to make sure that your database is designed just the way you think it
should be? Use these test functions and rest easy.

### `has_table( schema, table, description )` ###
### `has_table( table, description )` ###
### `has_table( table )` ###

    SELECT has_table(
        'myschema',
        'sometable',
        'I got myschema.sometable'
    );

This function tests whether or not a table exists in the database. The first
argument is a schema name, the second is a table name, and the third is the
test description. If you omit the schema, the table must be visible in the
search path. If you omit the test description, it will be set to "Table
`:table` should exist".

### `has_view( schema, view, description )` ###
### `has_view( view, description )` ###
### `has_view( view )` ###

    SELECT has_view(
        'myschema',
        'someview',
        'I got myschema.someview'
    );

Just like `has_table()`, only it tests for the existence of a view.

### `has_column( schema, table, column, description )` ###
### `has_column( table, column, description )` ###
### `has_column( table, column )` ###

    SELECT has_column(
        'myschema',
        'sometable',
        'somecolumn',
        'I got myschema.sometable.somecolumn'
    );

Tests whether or not a column exists in a given table or view. The first
argument is the schema name, the second the table name, the third the column
name, and the fourth is the test description. If the schema is omitted, the
table must be visible in the search path. If the test description is omitted,
it will be set to "Column `:table`.`:column` should exist".

### `col_not_null( schema, table, column, description )` ###
### `col_not_null( table, column, description )` ###
### `col_not_null( table, column )` ###

    SELECT col_not_null(
        'myschema',
        'sometable',
        'somecolumn',
        'Column myschema.sometable.somecolumn should be NOT NULL'
    );

Tests whether the specified column has a `NOT NULL` constraint. The first
argument is the schema name, the second the table name, the third the column
name, and the fourth is the test description. If the schema is omitted, the
table must be visible in the search path. If the test description is omitted,
it will be set to "Column `:table`.`:column` should be NOT NULL". Note that
this test will fail if the table or column in question does not exist.

### `col_is_null( schema, table, column, description )` ###
### `col_is_null( table, column, description )` ###
### `col_is_null( table, column )` ###

    SELECT col_is_null(
        'myschema',
        'sometable',
        'somecolumn',
        'Column myschema.sometable.somecolumn should allow NULL'
    );

This function is the inverse of `col_not_null()`: the test passes if the
column does not have a `NOT NULL` constraint. The first argument is the schema
name, the second the table name, the third the column name, and the fourth is
the test description. If the schema is omitted, the table must be visible in
the search path. If the test description is omitted, it will be set to "Column
`:table`.`:column` should allow NULL". Note that this test will fail if the
table or column in question does not exist.

### `col_type_is( schema, table, column, type, description )` ###
### `col_type_is( table, column, type, description )` ###
### `col_type_is( table, column, type )` ###

    SELECT col_type_is(
        'myschema',
        'sometable',
        'somecolumn',
        'numeric(10,2)',
        'Column myschema.sometable.somecolumn should be type text'
    );

This function tests that the specified column is of a particular type. If it
fails, it will emit diagnostics naming the actual type. The first argument is
the schema name, the second the table name, the third the column name, the
fourth the type, and the fifth is the test description. If the schema is
omitted, the table must be visible in the search path. If the test description
is omitted, it will be set to "Column `:table`.`:column` should be type
`:type`". Note that this test will fail if the table or column in question
does not exist.

The type argument should be formatted as it would be displayed in the view of
a table usin the `\d` command in `psql`. For example, if you have a numeric
column with a precision of 8, you should specify "numeric(8,0)". If you
created a `varchar(64)` column, you should pass the type as "character
varying(64)".

If the test fails, it will output useful diagnostics. For example this test:

    SELECT col_type_is( 'pg_catalog', 'pg_type', 'typname', 'text' );

Will produce something like this:

    # Failed test 138: "Column pg_catalog.pg_type.typname should be type text
    #         have: name
    #         want: text

### `col_default_is( schema, table, column, default, description )` ###
### `col_default_is( table, column, default, description )` ###
### `col_default_is( table, column, type )` ###

    SELECT col_default_is(
        'myschema',
        'sometable',
        'somecolumn',
        'howdy'::text,
        'Column myschema.sometable.somecolumn should default to ''howdy'''
    );

Tests the default value of a column. If it fails, it will emit diagnostics
showing the actual default value. The first argument is the schema name, the
second the table name, the third the column name, the fourth the default
value, and the fifth is the test description. If the schema is omitted, the
table must be visible in the search path. If the test description is omitted,
it will be set to "Column `:table`.`:column` should default to `:default`".
Note that this test will fail if the table or column in question does not
exist.

The default argument must have an unambiguous type in order for the call to
succeed. If you see an error such as 'ERROR: could not determine polymorphic
type because input has type "unknown"', it's because you forgot to cast the
expected value to its proper type. IOW, this will fail:

    SELECT col_default_is( 'tab', 'name', 'foo' );

But this will not:

    SELECT col_default_is( 'tab', 'name', 'foo'::text );

You can also test for functional defaults. Just specify the function call as a
string:

    SELECT col_default_is( 'user', 'created_at', 'now()' );

If the test fails, it will output useful diagnostics. For example, this test:

    SELECT col_default_is(
        'pg_catalog',
        'pg_type',
        'typname',
        'foo'::text,
        'check typname'
    );

Will produce something like this:

    # Failed test 152: "check typname"
    #         have: NULL
    #         want: foo

### `has_pk( schema, table, description )` ###
### `has_pk( table, description )` ###
### `has_pk( table )` ###

    SELECT has_pk(
        'myschema',
        'sometable',
        'Table myschema.sometable should have a primary key'
    );

Tests whether or not a table has a primary key. The first argument is the
schema name, the second the table name, the the third is the test description.
If the schema is omitted, the table must be visible in the search path. If the
test description is omitted, it will be set to "Table `:table` should have a
primary key". Note that this test will fail if the table in question does not
exist.

### `has_fk( schema, table, description )` ###
### `has_fk( table, description )` ###
### `has_fk( table )` ###

    SELECT has_fk(
        'myschema',
        'sometable',
        'Table myschema.sometable should have a foreign key constraint'
    );

Tests whether or not a table has a foreign key constraint. The first argument
is the schema name, the second the table name, the the third is the test
description. If the schema is omitted, the table must be visible in the search
path. If the test description is omitted, it will be set to "Table `:table`
should have a foreign key constraint". Note that this test will fail if the
table in question does not exist.

### `col_is_pk( schema, table, column, description )` ###
### `col_is_pk( schema, table, column[], description )` ###
### `col_is_pk( table, column, description )` ###
### `col_is_pk( table, column[], description )` ###
### `col_is_pk( table, column )` ###
### `col_is_pk( table, column[] )` ###

    SELECT col_is_pk(
        'myschema',
        'sometable',
        'id',
        'Column myschema.sometable.id should be a primary key'
    );

    SELECT col_is_pk(
        'persons',
        ARRAY['first', 'last'],
    );

Tests whether the specified column or columns in a table is/are the primary
key for that table. If it fails, it will emit diagnostics showing the actual
primary key columns, if any. The first argument is the schema name, the second
the table name, the third the column name or an array of column names, and the
fourth is the test description. If the schema is omitted, the table must be
visible in the search path. If the test description is omitted, it will be set
to "Column `:table`.`:column` should be a primary key". Note that this test
will fail if the table or column in question does not exist.

If the test fails, it will output useful diagnostics. For example this test:

    SELECT col_is_pk( 'pg_type', 'id' );

Will produce something like this:

    # Failed test 178: "Column pg_type.id should be a primary key"
    #         have: {}
    #         want: {id}

### `col_is_fk( schema, table, column, description )` ###
### `col_is_fk( schema, table, column[], description )` ###
### `col_is_fk( table, column, description )` ###
### `col_is_fk( table, column[], description )` ###
### `col_is_fk( table, column )` ###
### `col_is_fk( table, column[] )` ###

    SELECT col_is_fk(
        'myschema',
        'sometable',
        'other_id',
        'Column myschema.sometable.other_id should be a foreign key'
    );

    SELECT col_is_fk(
        'contacts',
        ARRAY['first', 'last'],
    );

Just like `col_is_fk()`, except that it test that the column or array of
columns are a primary key.

### `has_unique( schema, table, description )` ###
### `has_unique( table, description )` ###
### `has_unique( table )` ###

    SELECT has_unique(
        'myschema',
        'sometable',
        'Table myschema.sometable should have a unique constraint'
    );

Tests whether or not a table has a unique constraint. The first argument is
the schema name, the second the table name, the the third is the test
description. If the schema is omitted, the table must be visible in the search
path. If the test description is omitted, it will be set to "Table `:table`
should have a unique constraint". Note that this test will fail if the table
in question does not exist.

### `col_is_unique( schema, table, column, description )` ###
### `col_is_unique( schema, table, column[], description )` ###
### `col_is_unique( table, column, description )` ###
### `col_is_unique( table, column[], description )` ###
### `col_is_unique( table, column )` ###
### `col_is_unique( table, column[] )` ###

    SELECT col_is_unique(
        'myschema',
        'sometable',
        'other_id',
        'Column myschema.sometable.other_id should have a unique constraint'
    );

    SELECT col_is_unique(
        'contacts',
        ARRAY['first', 'last'],
    );

Just like `col_is_pk()`, except that it test that the column or array of
columns have a unique constraint on them.

### `has_check( schema, table, description )` ###
### `has_check( table, description )` ###
### `has_check( table )` ###

    SELECT has_check(
        'myschema',
        'sometable',
        'Table myschema.sometable should have a check constraint'
    );

Tests whether or not a table has a check constraint. The first argument is the
schema name, the second the table name, the the third is the test description.
If the schema is omitted, the table must be visible in the search path. If the
test description is omitted, it will be set to "Table `:table` should have a
check constraint". Note that this test will fail if the table in question does
not exist.

### `col_has_check( schema, table, column, description )` ###
### `col_has_check( schema, table, column[], description )` ###
### `col_has_check( table, column, description )` ###
### `col_has_check( table, column[], description )` ###
### `col_has_check( table, column )` ###
### `col_has_check( table, column[] )` ###

    SELECT col_has_check(
        'myschema',
        'sometable',
        'other_id',
        'Column myschema.sometable.other_id should have a check constraint'
    );

    SELECT col_has_check(
        'contacts',
        ARRAY['first', 'last'],
    );

Just like `col_is_pk()`, except that it test that the column or array of
columns have a check constraint on them.

Diagnostics
-----------

If you pick the right test function, you'll usually get a good idea of what
went wrong when it failed. But sometimes it doesn't work out that way. So here
we have ways for you to write your own diagnostic messages which are safer
than just `\echo` or `SELECT foo`.

### `diag( text )` ###

Returns a diagnostic message which is guaranteed not to interfere with
test output. Handy for this sort of thing:

    -- Output a diagnostic message if the collation is not en_US.UTF-8.
    SELECT diag(
         E'These tests expect LC_COLLATE to be en_US.UTF-8,\n'
      || 'but yours is set to ' || setting || E'.\n'
      || 'As a result, some tests may fail. YMMV.'
    )
      FROM pg_settings
     WHERE name = 'lc_collate'
       AND setting <> 'en_US.UTF-8';

Which would produce:

    # These tests expect LC_COLLATE to be en_US.UTF-8,
    # but yours is set to en_US.ISO8859-1.
    # As a result, some tests may fail. YMMV.

Conditional Tests
-----------------

Sometimes you might have tests that you want to pass, but you haven't gotten
around to implementing the logic required to make them pass. pgTAP allows you
to declare that such tests are supposed to fail but will work in the future.
This is known as a "todo test."

### `todo( why, how_many )` ###

Declares a series of tests that you expect to fail and why. Perhaps it's
because you haven't fixed a bug or haven't finished a new feature:

    todo('URIGeller not finished', 2);

    \set card '\'' Eight of clubs '\''
    SELECT is( URIGeller.yourCard(), :card, 'Is THIS your card?' );
    SELECT is( URIGeller.bendSpoon(), 'bent', 'Spoon bending, how original' );

With `todo()`, `:how_many` specifies how many tests are expected to fail.
pgTAP will run the tests normally, but print out special flags indicating they
are "todo" tests. The test harness will interpret these failures as ok. Should
any todo test pass, the harness will report it as an unexpected success. You
then know that the thing you had todo is done and can remove the call to
`todo()`.

The nice part about todo tests, as opposed to simply commenting out a block of
tests, is that they're like a programmatic todo list. You know how much work
is left to be done, you're aware of what bugs there are, and you'll know
immediately when they're fixed.

To Do
-----

* Add a test function to test test functions and update the test script to
  use it.
* Update the Makefile to process pg_prove and set the proper path to Perl on
  the shebang line. Will likely require a `$(PERL)` environment variable.
* Update the Makefile to require TAP::Harness.
* Update the Makefile to alter the source as appropriate for older versions
  of PostgreSQL.

Suported Versions
-----------------

pgTAP has been tested on the following builds of PostgreSQL:

* PostgreSQL 8.3.1 on i386-apple-darwin9.2.2

If you know of others, please submit them! Use
`psql -d template1 -c 'SELECT VERSION()'` to get the formal build version and OS.

Author
------
[David E. Wheeler](http://justatheory.com/)

Credits
-------

* Michael Schwern and chromatic for Test::More.
* Adrian Howard for Test::Exception.

Copyright and License
---------------------

Copyright (c) 2008 Kineticode, Inc. Some rights reserved.

Permission to use, copy, modify, and distribute this software and its
documentation for any purpose, without fee, and without a written agreement is
hereby granted, provided that the above copyright notice and this paragraph
and the following two paragraphs appear in all copies.

IN NO EVENT SHALL KINETICODE BE LIABLE TO ANY PARTY FOR DIRECT, INDIRECT,
SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, INCLUDING LOST PROFITS, ARISING
OUT OF THE USE OF THIS SOFTWARE AND ITS DOCUMENTATION, EVEN IF KINETICODE HAS
BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

KINETICODE SPECIFICALLY DISCLAIMS ANY WARRANTIES, INCLUDING, BUT NOT LIMITED
TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
PURPOSE. THE SOFTWARE PROVIDED HEREUNDER IS ON AN "AS IS" BASIS, AND
KINETICODE HAS NO OBLIGATIONS TO PROVIDE MAINTENANCE, SUPPORT, UPDATES,
ENHANCEMENTS, OR MODIFICATIONS.
